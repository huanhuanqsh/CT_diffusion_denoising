# 基于开源项目Dn-Dp的CT图像降噪扩散模型训练研究报告

- [说明](#说明)
- [材料和方法](#材料和方法)
- [结果](#结果)
- [讨论](#讨论)
- [结论](#结论)

## 说明

在医学成像领域，低剂量CT（Low-Dose Computed Tomography）技术因其辐射暴露量小而备受青睐，但低剂量会出现图像噪声增多的问题，由此降低了诊断的准确性和可靠性。因此，在医学影像中，低剂量CT图像的去噪是一项至关重要的任务。近年来，基于监督学习的深度学习方法在这一领域取得了显著进展，为解决此类问题提供了新途径。本文基于开源项目“Dn-Dp”[1]，介绍了一种新颖的基于扩散概率先验的零样本低剂量CT图像降噪方法，并通过实验训练验证其有效性。

## 材料和方法

### 模型概述

基于监督学习的深度学习方法的模型训练通常需要海量的低剂量和正常剂量CT图像对作为训练数据，这在临床环境中相对难以获取。现有的无监督深度学习方法往往需要使用大量低剂量CT图像进行训练，或者依赖于特别设计的数据采集流程来获取训练数据。为了解决这些限制，该项目提出了一种新颖的无监督方法，该方法仅在训练阶段利用正常剂量CT图像，从而实现零样本低剂量CT图像的去噪。

具体来说，此方法利用扩散模型首先训练了一个级联无条件扩散模型，能够从低分辨率到高分辨率生成高质量的正常剂量CT图像。级联架构使得高分辨率扩散模型的训练更加可行。随后，将低剂量CT图像引入扩散模型的反向过程中作为似然，并结合扩散模型提供的先验，通过迭代解决多个最大后验（MAP）问题以达到去噪目的。此外，提出了自适应调整在MAP估计中平衡似然和先验的系数的方法，使模型能适应低剂量CT图像中不同的噪声水平。

### 训练过程

- **环境配置**：

  - 云环境：Ubuntu20.04，CPU型号：Intel(R) Xeon(R) Platinum 8260C CPU @ 2.30GHz
  - GPU：NVIDIA GeForce RTX 3090，显卡内存：24G
  - 软件环境：Python 3.10，Pytorch 2.1.1，CUDA 11.8，并通过`pip install -r requirements.txt`安装项目所需依赖包

- **数据准备**：

  本研究使用的数据集包含两部分：

  一是低剂量CT图像和相应的高剂量CT图像作为配对，用于训练和验证扩散模型的去噪能力。

  二是独立的测试集，包含低剂量CT图像，用于最终模型性能的评估。所有图像均来自临床数据，涵盖腹部CT扫描，确保模型的泛化性能。图像经过预处理，包括标准化、归一化和尺寸调整，以适配合统一的输入要求。

  > 注：下载的源数据为IMA格式，代码转换为png格式，大小：512*512

- **参数配置**：

  - 使用YAML、JSON配置文件调整训练参数，如模型路径、数据预处理尺寸、DDIM配置、去噪参数等。
  - 将测试图像放置在指定的`input_folder`，输出保存在`output_folder`。

- **模型训练**：使用`sr_training.py`和`sample_training.py`脚本来训练超分辨率和无条件扩散模型。为了提升高分辨率模型训练效果，采取如下策略：

  - 引入patching技术[2]，类似于ViT架构的分块变换，以减少采样时间和内存消耗。
  - 使用Progressive Distillation减少采样步骤，每次迭代减半，直到模型能在较少步骤下维持相似的去噪质量为止。
  - 针对高分辨率模型，增加深U-Net的深度。

### 调优处理

- **测试数据处理**：对于测试数据中非`.png`格式或非uint16图像，调整读写函数。

  本报告测试数据是unit8图像，因此有如下调整：

  ```python
  def read_a_img(path):
      return imageio.imread(path) / 255.
  
  def save_a_img(img, path): 
      return imageio.imwrite(path, (img*255).astype(np.uint8))
  ```

- **度量标准**：采用FID分数（Frechet Inception Distance）衡量生成图像的质量，以及其他图像质量度量如PSNRMS-SSIM、PSNR等，以全面评估去噪效果。详见测试与评估小节。

- **超参数调优**：在训练过程中监控各项指标，通过调整超参数如lam0、a、b、c等，以AdaLam策略适应不同去噪模式，实现最优去噪效果。

### 测试与评估

- **训练过程度量**

无条件扩散模型训练情况： l_pix: 1.3170e-04 ，模型：*128_I200000_E5000_gen.pth、128_I200000_E5000_opt.pth*

超分辨率模型训练情况：PSNR: 5.3642e+01，模型：*128_512_I100000_E625_gen.pth、128_512_I100000_E625_opt.pth*

- **测试降噪图片**

开源项目提供了一套测试代码，具体操作如下：

1、通过`denoising.py -c ./config/Dn_128.yaml`，加载无条件扩散训练模型，对指定的低分辨率CT图像进行降噪，生成128*128低分辨的图片，保存在指定的输出目录中，并可选择计算指标以评估模型性能。如下图所示：

![L067_0001](./images/test.png)

2、通过`denoising.py -c ./config/Dn_128_512.yaml`，加载超分辨率训练模型，对高分辨率（512*512）CT图像，基于低分辨降噪图片作为条件，进行降噪，结果保存在指定输出目录中。

## 结果

通过实施上述训练与测试流程，项目成功地展示了扩散模型在降噪低剂量CT图像上的应用效果。具体成就包括：

- **降噪效果**：腹部CT图像在低分辨率下均实现了明显的去噪，同时保留了诊断细节。
- **高分辨率处理**：使用低分辨率去噪图像作为条件，对高分辨率CT图像的处理同样有效，证明了级联扩散模型的潜力。（基于开源项目提供的预训练模型测试证明有效，但基于本报告训练的模型此项尚未验证成功，研究中…）
- **效率提升**：分块技术的应用显著减少了采样时间，使得模型在资源有限的环境下也能高效运行。
- **模型结果**：本报告使用该项目训练的模型结果详见：[model](https://github.com/huanhuanqsh/CT_dd_model)，仅供进一步研究和应用。

## 讨论

**总结**：本报告研究通过开源项目“Dn-Dp”展现了扩散模型在CT图像降噪中的潜力，特别是低剂量情况下的应用，不仅提高了图像质量，还解决了传统降噪方法依赖海量成对数据的限制。分块技术的整合显著增强了模型在实际应用中的高可用性，相对降低了计算成本，但是模型训练和应用仍需高性能硬件支持。

**技术对比与启示**：与以往研究相比，本次报告研究了迭代次数减少对扩散模型效率的直接影响，并提出了切实可行的解决方案，而不仅仅是优化单次迭代的成本。为改善生成模型的效率问题提供了新的视角。此外，通过比较不同参数化与模型结构调整，体现了模型设计灵活性对于性能优化的重要性，为后续研究者提供了一定的实践指导。

**本报告现存问题**：本报告训练的模型，测试评估有一部分未完成：超分辨率模型的测试验证目前仍有问题，在研究调整中。

**未来方向**：未来工作可以进一步探索模型结构的优化，如更灵活的分块策略，以及如何在不同成像模式和临床场景中应用此方法。此外，对模型泛化能力的进一步研究，如跨设备和剂量水平的稳定表现，也是重要方向。

## 结论

综上所述，基于扩散模型的概率先验方法成功实现了低剂量CT图像的有效降噪，无需配对训练数据，展示了其在医学影像处理领域的广阔应用前景。通过结合分块技术等优化手段，项目不仅提升了模型性能，还确保了在实际部署中的效率，为低剂量CT成像的临床应用带来了实质性的进步。

**引用：**

[1] DeepXuan/Dn-Dp GitHub Repository. (2023). Available at: https://github.com/DeepXuan/Dn-Dp

[2] Improving Diffusion Model Efficiency Through Patching. Available at: https://arxiv.org/abs/2207.04316

[3] Progressive Distillation for Fast Sampling of Diffusion Models. Available at: https://arxiv.org/abs/2202.00512

[4] Pre-trained Cascaded Diffusion Models Download Link. Available at: https://drive.google.com/drive/folders/1sHWtDlUCO-4cb-v_ijR1i3c2PYqB44xs?usp=sharing
